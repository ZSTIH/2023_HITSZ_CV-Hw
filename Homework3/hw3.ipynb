{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "*This notebook includes both coding and written questions. Please hand in this notebook file with all the outputs and your answers to the written questions.*\n",
    "\n",
    "This assignment covers K-Means and mean shift methods for clustering and image segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from __future__ import print_function\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 8) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this assignment, you will use clustering algorithms to segment images. You will then use these segmentations to identify foreground and background objects.\n",
    "\n",
    "Your assignment will involve the following subtasks:\n",
    "- **K-means clustering**: Understand the principle of kmeans and implement K-Means clustering.\n",
    "- **Mean shift clustering**: Understand the principle of mean-shift and implement Mean Shift clustering.\n",
    "- **Results comparison**: Try the above two methods on the image segmentation task and compare the performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 K-means Clustering Algorithms (total 30 points)\n",
    "K-Means clustering is an unsupervised learning algorithm. There is no labeled data for this clustering, unlike in supervised learning. K-Means performs the division of objects into clusters that share similarities and are dissimilar to the objects belonging to another cluster. The K-Means clustering algorithm is an iterative process where you are trying to minimize the distance of the data point from the average data point in the cluster.\n",
    "\n",
    "<img src=./images/kmean_sample.gif width=100% />\n",
    "\n",
    "reference: https://www.linkedin.com/pulse/k-means-clustering-its-real-use-case-surayya-shaikh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random data points for clustering\n",
    "\n",
    "# Set seed for consistency\n",
    "np.random.seed(0)\n",
    "\n",
    "# Cluster 1\n",
    "mean1 = [-1, 0]\n",
    "cov1 = [[0.1, 0], [0, 0.1]]\n",
    "X1 = np.random.multivariate_normal(mean1, cov1, 100)\n",
    "\n",
    "# Cluster 2\n",
    "mean2 = [0, 1]\n",
    "cov2 = [[0.1, 0], [0, 0.1]]\n",
    "X2 = np.random.multivariate_normal(mean2, cov2, 100)\n",
    "\n",
    "# Cluster 3\n",
    "mean3 = [1, 0]\n",
    "cov3 = [[0.1, 0], [0, 0.1]]\n",
    "X3 = np.random.multivariate_normal(mean3, cov3, 100)\n",
    "\n",
    "# Cluster 4\n",
    "mean4 = [0, -1]\n",
    "cov4 = [[0.1, 0], [0, 0.1]]\n",
    "X4 = np.random.multivariate_normal(mean4, cov4, 100)\n",
    "\n",
    "# Merge two sets of data points\n",
    "X = np.concatenate((X1, X2, X3, X4))\n",
    "\n",
    "# Plot data points\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 K-Means Clustering (10 points)\n",
    "As discussed in class, K-Means is one of the most popular clustering algorithms. We have provided skeleton code for K-Means clustering in the file `segmentation.py`. Your first task is to finish implementing **`kmeans`** in `segmentation.py`. This version uses nested for loops to assign points to the closest centroid and compute a new mean for each cluster.\n",
    "\n",
    "We can manually implement the kmeans algorithm by looping through, but we can use numpy functions and broadcasting to make K-Means faster. This should run at least 10 times faster than the implementation of only `for looping`.\n",
    "\n",
    "If you are interested, you can compare the time overhead of using broadcasting and for loops, and record them. (Optional, no score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation import kmeans\n",
    "\n",
    "np.random.seed(0)\n",
    "start = time()\n",
    "assignments = kmeans(X, 4)\n",
    "end = time()\n",
    "\n",
    "kmeans_runtime = end - start\n",
    "\n",
    "print(\"kmeans running time: %f seconds.\" % kmeans_runtime)\n",
    "\n",
    "for i in range(4):\n",
    "    cluster_i = X[assignments==i]\n",
    "    plt.scatter(cluster_i[:, 0], cluster_i[:, 1])\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 K-Means Convergence (10 points)\n",
    "Implementations of the K-Means algorithm will often have the parameter `num_iters` to define the maximum number of iterations the algorithm should run for. Consider that we opt to not include this upper bound on the number of iterations, and that we define the termination criterion of the algorithm to be when the cost $L$ stops changing.\n",
    "\n",
    "Recall that $L$ is defined as the sum of squared distance between all points $x$ and their nearest cluster center $c$:\n",
    "\n",
    "$$L = \\sum_{i \\in clusters}\\sum_{x \\in cluster_i} (x - c_i)^2$$\n",
    "\n",
    "Show that for any set of points **$D$** and any number of clusters $k$, the K-Means algorithm will terminate in a finite number of iterations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n",
    "\n",
    "本题相当于是去证明，如果以 $L$ 不再改变为迭代终止条件（不考虑迭代次数上限 `num_iters`），给定一组点集 $D$ 和任意的聚类数 $k$，K-Means 算法都将会在有限次迭代后终止。\n",
    "\n",
    "首先，考虑到K-Means算法的工作原理，它的迭代过程中涉及两个主要步骤：分配步骤（Assignment step）和更新步骤（Update step）。在**分配步骤**中，算法会根据每个数据点x与其最近的聚类中心c的距离来将数据点分配给相应的聚类。在**更新步骤**中，算法会重新计算每个聚类的中心，通过计算每个聚类中所有数据点的平均值来得到新的聚类中心。\n",
    "\n",
    "我们考虑 $L$ 的定义：\n",
    "\n",
    "$$L = \\sum_{i \\in clusters}\\sum_{x \\in cluster_i} (x - c_i)^2$$\n",
    "\n",
    "假设在进行了 $n$ 轮迭代后，$L$ 的大小为 $L_n$。现在对于第 $(n+1)$ 轮，先进行分配步骤，分配完成后 $L$ 的大小变为 $L_n^{'}$。由于分配过程是将数据点分配给距离更小的聚类中心，在这个过程中，距离总和只可能变小或者保持不变，不可能增大。因此我们有 $L_n^{'} \\leq L_n$。\n",
    "\n",
    "对于第 $(n+1)$ 轮的更新步骤，我们设更新完后的 $L$ 为$L_n^{''}$。并设 $L=C_1+C_2+C_3+...+C_k$，其中 $C_1 \\sim C_k$ 是不同聚类中心内部的距离总和。显然有：\n",
    "\n",
    "$$C_j = \\sum_{x \\in cluster_j} (x - c_j)^2 = \\sum_{x \\in cluster_j} (c_j - x)^2$$\n",
    "\n",
    "求出 $C_j$ 关于$ c_j$ 的偏导，得到：\n",
    "\n",
    "$$\\frac{\\partial C_j}{\\partial c_j} = \\sum_{x \\in cluster_j} 2 \\cdot (c_j - x)$$\n",
    "\n",
    "故$\\frac{\\partial C_j}{\\partial c_j} = 0$的时候，$c_j$的值恰好为当前聚类中所有点的平均值 $\\overline{x_j}$ （也就是更新步骤计算出的新均值）。注意到，$c_j < \\overline{x_j}$时，$\\frac{\\partial C_j}{\\partial c_j} < 0$，$C_j$ 随$ c_j$的增大而减小；$c_j > \\overline{x_j}$时，$\\frac{\\partial C_j}{\\partial c_j} > 0$，$C_j$ 随$ c_j$的增大而增大。因此，当某个聚类中的所有点保持不变，并将聚类中心设置为当前聚类点的平均值时，能让 $C_j$ 取到最小值。\n",
    "\n",
    "因此，在更新步骤，同样可推出，距离总和只可能变小或者保持不变，不可能增大。因此我们有 $L_{n+1}=L_n^{''} \\leq L_n^{'} \\leq L_n$。\n",
    "\n",
    "所以可以进一步得到$L_{1} \\geq L_{2} \\geq L_{3} \\geq L_{4} \\geq ... \\geq L_{n} \\geq L_{n+1}$。$L$ 显然非负（即$L \\geq 0$）。根据**极限的单调有界定理**，可以得到$\\lim_{n \\to \\infty}L_n = P$（$P$ 为某一定常数）。\n",
    "\n",
    "另一方面，由于计算机中，实数使用浮点数的方式来存储，存储位数和存储精度有限。因此在判定相等的时候，只要两个数的差距小于某个阈值即会认为相等。再结合 $\\lim_{n \\to \\infty}L_n = P$（$P$ 为某一定常数），可知经过有限步骤后，计算机会判定 $L$ 不再改变，并终止迭代。\n",
    "\n",
    "综上所述，即便不使用 `num_iters`，K-Means 算法仍会在有限次迭代后终止。\n",
    "\n",
    "证毕."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Image Segmentation based on K-means (10 points)\n",
    "When we use kmeans for image segmentation, the color information of pixels is used for clustering, so each of our pixels can be regarded as a vector composed of R, G, and B, and RGB is our color feature.\n",
    "\n",
    "The specific process is similar to our example above, but the calculation object is changed from a scalar to a 3-dimensional vector.\n",
    "\n",
    "Please implement the `kmean_color` function in `segmentation.py` and call it to complete the segmentation of color images. (very similar to `kmeans function`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation import kmeans_color\n",
    "img = io.imread('example.jpg')\n",
    "#img = img[...,[2,1,0]]\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "k=2\n",
    "cluster_color=[[255,0,0],[0,255,0],[0,0,255],[[255,255,0]],[255,0,255],[[0,255,255]]]\n",
    "start = time()\n",
    "assignments = kmeans_color(img, k)\n",
    "end = time()\n",
    "\n",
    "print(\"kmeans_clustering running time: %f seconds.\" % (end - start))\n",
    "res_img=np.array(img)\n",
    "for i in range(k):\n",
    "    res_img[assignments==i]=cluster_color[i]\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(res_img)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can try different values of k and number of iterations and observe the difference in the results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Mean Shift Clustering (total 50 points)\n",
    "### 2.1 Mean Shift\n",
    "Mean shift is a procedure for locating the maxima—the modes—of a density function given discrete data sampled from that function.  This is an iterative method, and we start with an initial estimate $x$, Let a kernel function $K(x_{i}-x)$ be given. This function determines the weight of nearby points for re-estimation of the mean. Typically a Gaussian kernel on the distance to the current estimate is used, $K(x_{i}-x)=e^{-c||x_{i}-x||^{2}}$. The weighted mean of the density in the window determined by $K$ is:\n",
    "\n",
    "$$ m(x)=\\frac{\\sum_{x_{i} \\in N(x)} K(x_{i}-x) x_{i}}{\\sum_{x_{i}\\in N(x)}K(x_{i}-x)} $$\n",
    "\n",
    "where $N(x)$ is the neighborhood of $x$, a set of points for which $K(x_{i}-x)\\neq 0$. The difference $m(x)-x$ between mean and specific point is called mean shift in Fukunaga and Hostetler. The mean-shift algorithm now sets $x\\leftarrow m(x)$, and repeats the extimation until $m(x)$ converges."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "mean shift example: specific one sample:\n",
    "\n",
    "It will \"move\" towards the direction with the highest density within a fixed range. \"Move' in the segmentation is just an abstract way of saying that the point representing the pixel is more likely to belong to the category of the pixel with the highest density.\n",
    "\n",
    "<img src=./images/mean-shift-vector.gif width=100% />\n",
    "\n",
    "mean shift example: all samples:\n",
    "<img src=./images/mean-shift.gif width=100% />\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's use the meanshift function in sklearn to try it out on the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "bandwidth = estimate_bandwidth(X, quantile=0.2, n_samples=1000)\n",
    "\n",
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "ms.fit(X)\n",
    "labels = ms.labels_\n",
    "k=len(list(set(labels)))\n",
    "for i in range(k):\n",
    "    cluster_i = X[labels==i]\n",
    "    plt.scatter(cluster_i[:, 0], cluster_i[:, 1])\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Implementation of Mean Shift (30 points)\n",
    "We try to implement the mean shift algorithm manually. the process is:\n",
    "\n",
    "- **(1)**: Calculate the mean vector for each sample;\n",
    "- **(2)**: Offset the mean vector from which samples are computed;\n",
    "- **(3)**: Repeat the previous two processes, and set the iteration stop condition, such as the mean shift is less than a certain threshold;\n",
    "- **(4)**: Samples that converge to the same point are considered to be members of the same cluster class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation import segmIm\n",
    "img = io.imread('./example.jpg')\n",
    "\n",
    "# 运行 Mean Shift 算法，超参可以自己调整\n",
    "res_img=segmIm(img, 20)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Since the mean shift algorithm usually calculates the mean vector for all points in the whole image, the convergence speed is slow. If the image is large, we generally perform compression processing. (Our example is already compressed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(res_img)\n",
    "#输出的是灰度图，并不是前景的mask\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Calculate the performance (10 points)\n",
    "Match the prediction result with gt pixel by pixel, finish the `compute_accuracy` function in the `segmentation.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation import compute_accuracy\n",
    "from skimage import color\n",
    "#Set the foreground to 0, the background to 0\n",
    "pred_mask=res_img\n",
    "gt=np.array(io.imread('./gt.png'))[:,:,:3]# Omit the fourth channel\n",
    "gt=color.rgb2gray(gt)\n",
    "gt_mask=(gt <= 0.5).astype(int)\n",
    "\n",
    "#筛选前景，超参可调整\n",
    "pred_mask=(pred_mask >= 0.5).astype(int)\n",
    "\n",
    "acc=compute_accuracy(pred_mask, gt_mask)\n",
    "print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.4 Question (10 points)\n",
    "In the above attempts, it can be found that the clustering process of shift mean is slow when facing large images. Please give several methods to speed up the algorithm. (including pre-processing or post-processing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Your answer here:**\n",
    "\n",
    "可以使用以下方法来加速 **shift mean** 的聚类过程：\n",
    "- 预处理优化方法：\n",
    "    - 对大图像提前进行压缩。例如，可以将大图像按比例缩小，以降低图像的分辨率。\n",
    "    - 对大图像提前进行分割，划分为多个较小的区域，然后再对每个区域进行独立的聚类。\n",
    "    - 数据降维：如果数据维度非常高，可以使用降维技术（如主成分分析）将数据降低到较低的维度。这可以减少计算量，并提高Mean-Shift的速度。\n",
    "    - 数据采样：如果数据集很大，可以考虑对数据进行采样，选择一部分代表性的样本进行Mean-Shift。这样可以减少计算的复杂性，并在保留数据集结构的同时提高速度。\n",
    "    - 核函数选择：Mean-Shift方法中的核函数选择也会影响速度。可以尝试使用简单的核函数（如高斯核函数）替代复杂的核函数。简化核函数可以减少计算量，并加速Mean-Shift的收敛速度。\n",
    "    - 簇初始化：使用一些快速的聚类算法（如K-Means）来初始化簇的中心点。然后，将这些中心点作为Mean-Shift算法的初始点，可以加速算法的收敛速度。\n",
    "- 后处理优化方法：\n",
    "    - 聚类结果剪枝：在Mean-Shift的一轮迭代结束后，可以对聚类结果进行剪枝。如果某个聚类簇的样本数量太少，可以将其归并到邻近的簇中。这样可以减少聚类结果中的噪声，并减小簇的数量。\n",
    "    - 并行计算：可以考虑使用并行计算技术（如多线程或分布式计算）来加速Mean-Shift的计算过程。将数据分成多个子集，并在不同的处理单元上并行计算，可以显著提高计算速度。\n",
    "    - 簇合并：在Mean-Shift的一轮迭代结束后，可以对聚类结果进行簇合并。如果存在非常接近的簇，则可以将它们合并成一个簇，从而减少最终的簇的数量。这样可以降低后处理的计算复杂度。\n",
    "    - 收敛条件优化：Mean-Shift方法中的收敛条件可以调整。可以根据实际需求降低收敛精度，从而减少迭代次数。这样可以加速Mean-Shift的收敛过程。\n",
    "    - 算法上优化。例如，将End Point附近半径范围内的所有点都归属为与End Point相同的Cluster，或者将Mean Shift移动路径上的r/c范围内的所有Point都归属于与End Point相同的Cluster。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Comparison of kmeans and mean shift (20 points)\n",
    "We want to specifically compare the performance of kmeans and mean shift methods on foreground segmentation.\n",
    "\n",
    "For foreground segmentation, we only need to segment certain specific objects, such as cats, dogs, beds, and so on. The objects that need to be segmented on the small amount of data we use for comparison are all cats, but the number of cats is variable.\n",
    "\n",
    "For mean shift, two clusters are generated most of the time in our task (There are many categories, choose the appropriate category as the prospect according to your needs), and for kmeans, we only need to set k=2.\n",
    "\n",
    "Please use the previously implemented code in the following block to traverse the entire dataset and output the accuracy results of using the kmeans and mean shift methods on each image.\n",
    "\n",
    "It should be emphasized that because the mean shift algorithm is slow, you can use the image compression method to compress the image first, but the aspect ratio of the image cannot be changed (our recommendation is 128*102)\n",
    "\n",
    "How to determine which of the outcomes is the prediction we want?\n",
    "   It can be calculated with that the max area of overlapping of the groundtruth or to observe manually.\n",
    "\n",
    "Note: There is rgb noise in the ground truth image, it is not a complete black and white image, pay attention to the threshold of binarization.\n",
    "\n",
    "Note: allow flexible adjustment of hyperparameters for different images.\n",
    "\n",
    "And visualize each image: original; kmeans result; mean shift result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "image_files=os.listdir('./data/imgs')\n",
    "images=[]\n",
    "gts=[]\n",
    "masks=[]\n",
    "for i in image_files:\n",
    "    images.append(os.path.join('./data/imgs',i))\n",
    "    gts.append(os.path.join('./data/gt',i))\n",
    "for i in range(len(images)):\n",
    "    ### YOUR CODE HERE # 10 points\n",
    "    pass\n",
    "    img = io.imread(images[i])\n",
    "    #kmeans\n",
    "    km_mask=kmeans_color(img, 2)\n",
    "    km_mask=(km_mask >= 0.5).astype(int)\n",
    "    #mean shift\n",
    "    ms_mask=segmIm(img, 2)\n",
    "    ms_mask=(ms_mask >= 0.5).astype(int)\n",
    "    #gt\n",
    "    gt=np.array(io.imread(gts[i]))[:,:,:3]# Omit the fourth channel\n",
    "    gt=color.rgb2gray(gt)\n",
    "    gt_mask=(gt <= 0.5).astype(int)\n",
    "    ### END YOUR CODE\n",
    "    #kmeans\n",
    "    masks.append([km_mask,ms_mask,gt_mask])\n",
    "    #output three masks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#visualize\n",
    "plt.figure()\n",
    "\n",
    "for i in range(len(masks)):\n",
    "    ### YOUR CODE HERE # 10 points\n",
    "    km_acc=compute_accuracy(masks[i][2], masks[i][0])\n",
    "    ms_acc=compute_accuracy(masks[i][2], masks[i][1])\n",
    "    pass\n",
    "    ### END YOUR CODE\n",
    "    print(i, \" kmeans: \", km_acc, ' , mean_shift: ', ms_acc)\n",
    "\n",
    "for i in range(len(masks)):\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(masks[i][2])\n",
    "    plt.title('gt')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(masks[i][0])\n",
    "    plt.title('kmeans')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(masks[i][1])\n",
    "    plt.title('mean shift')\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "visualize the results, for example:\n",
    "<img src=./images/visual.png width=100% />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('cs131')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ae52c0e087ae86afd3aef01e4a328a9c24392764432b5f2b2a1686052aeaae8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
